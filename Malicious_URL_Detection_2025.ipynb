{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Selma266/Malicious-URL-Detection/blob/main/Malicious_URL_Detection_2025.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YAOikKsTEClu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b97a8955-0c81-490b-f6e4-9c67f9d71927"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RIy2qDS7EuCG"
      },
      "source": [
        "Chargement Phishing URLs dataset + pr√©traitement"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7_WiYzr2Erh5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "a92ee026-a246-498a-9181-138393053a0f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                 url      label\n",
              "0  https://docs.google.com/presentation/d/e/2PACX...  malicious\n",
              "1    https://btttelecommunniccatiion.weeblysite.com/  malicious\n",
              "2                        https://kq0hgp.webwave.dev/  malicious\n",
              "3  https://brittishtele1bt-69836.getresponsesite....  malicious\n",
              "4         https://bt-internet-105056.weeblysite.com/  malicious"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bfbcc7e6-99a7-44e4-a004-119683a90f21\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>url</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>https://docs.google.com/presentation/d/e/2PACX...</td>\n",
              "      <td>malicious</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>https://btttelecommunniccatiion.weeblysite.com/</td>\n",
              "      <td>malicious</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>https://kq0hgp.webwave.dev/</td>\n",
              "      <td>malicious</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>https://brittishtele1bt-69836.getresponsesite....</td>\n",
              "      <td>malicious</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>https://bt-internet-105056.weeblysite.com/</td>\n",
              "      <td>malicious</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bfbcc7e6-99a7-44e4-a004-119683a90f21')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-bfbcc7e6-99a7-44e4-a004-119683a90f21 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-bfbcc7e6-99a7-44e4-a004-119683a90f21');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "import pandas as pd #la biblioth√®que Pandas, utilis√©e pour la manipulation et l‚Äôanalyse de donn√©es tabulaires.\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/Phishing URLs_cleaned.csv\")  # read dataset url,label  #Chargement du dataset\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NuMJn3xiFSbp"
      },
      "source": [
        "Suppression des lignes redondantes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KfXTI-HNFUyk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea0434eb-a084-45a4-ed8e-267d1dbb8912"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before removing duplicates:\n",
            "Shape: (504983, 2)\n",
            "\n",
            "After removing duplicates:\n",
            "Shape: (504933, 2)\n"
          ]
        }
      ],
      "source": [
        "# BEFORE removing duplicates\n",
        "print(\"Before removing duplicates:\")\n",
        "print(\"Shape:\", df.shape)\n",
        "\n",
        "# Step 2: Remove duplicate rows\n",
        "df = df.drop_duplicates()   #Suppression des doublons\n",
        "\n",
        "# AFTER removing duplicates\n",
        "print(\"\\nAfter removing duplicates:\")\n",
        "print(\"Shape:\", df.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2QY2MMWFOZr"
      },
      "source": [
        "Supprimer les NaN+ Conversion label en valeur Numeriques"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_dzzNDwxFgY2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79b45fcb-280a-43c9-cc3d-a523b139eafc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "label\n",
            "0    345738\n",
            "1    159195\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Supprimer les lignes o√π url ou label est NaN\n",
        "df = df.dropna(subset=[\"url\", \"label\"]).reset_index(drop=True)  #reset_index(drop=True) R√©initialise l‚Äôindex du DataFrame\n",
        "# strip() supprime les espaces au d√©but et √† la fin URL\n",
        "df[\"url\"] = df[\"url\"].str.strip()\n",
        "# Conversion des labels texte en valeurs num√©riques\n",
        "df[\"label\"] = df[\"label\"].map({\"benign\": 0, \"malicious\": 1}).astype(int) #Encodage des labels\n",
        "print(df[\"label\"].value_counts()) #V√©rification de la distribution des classes Afichages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Seyw9c3TGJUM"
      },
      "source": [
        "Creation des 3 distributions dataset1(50% 50%),dataset2(90% 10%)et dataset(10%-90%)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-4DE265HGb9n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e4a70c9-b4f1-4d56-dc1e-b514ca78925a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "URLs b√©nignes disponibles: 345738\n",
            "URLs malveillantes disponibles: 159195\n",
            "Total URLs disponibles: 504933\n",
            "\n",
            "============================================================\n",
            "CR√âATION DES DATASETS\n",
            "============================================================\n",
            "\n",
            "üìä DATASET 1 - BALANCED (50-50):\n",
            "   Total samples: 176882\n",
            "   Distribution:\n",
            "label\n",
            "0    88441\n",
            "1    88441\n",
            "Name: count, dtype: int64\n",
            "   Pourcentages:\n",
            "label\n",
            "0    50.0\n",
            "1    50.0\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "üìä DATASET 2 - IMBALANCED (90% benign - 10% malicious):\n",
            "   Total samples: 176882\n",
            "   Distribution:\n",
            "label\n",
            "0    159194\n",
            "1     17688\n",
            "Name: count, dtype: int64\n",
            "   Pourcentages:\n",
            "label\n",
            "0    90.000113\n",
            "1     9.999887\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "üìä DATASET 3 - IMBALANCED (10% benign - 90% malicious):\n",
            "   Total samples: 176882\n",
            "   Distribution:\n",
            "label\n",
            "0     17688\n",
            "1    159194\n",
            "Name: count, dtype: int64\n",
            "   Pourcentages:\n",
            "label\n",
            "0     9.999887\n",
            "1    90.000113\n",
            "Name: proportion, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "#G√©n√®re les trois distributions exp√©rimentales √† partir du m√™me dataset source.\n",
        "import pandas as pd\n",
        "# S√©pare le dataset en deux sous-ensembles selon la classe (b√©nigne / malveillante).\n",
        "benign = df[df['label'] == 0]\n",
        "malicious = df[df['label'] == 1]\n",
        "#Affiche le nombre d‚Äô√©chantillons par classe pour v√©rifier la disponibilit√© des donn√©es.\n",
        "print(f\"URLs b√©nignes disponibles: {len(benign)}\")\n",
        "print(f\"URLs malveillantes disponibles: {len(malicious)}\")\n",
        "print(f\"Total URLs disponibles: {len(df)}\")\n",
        "\n",
        "# Taille fixe pour tous les datasets\\ to avoid 'Cannot take a larger sample than population error\n",
        "TOTAL_SIZE = 176883\n",
        "\n",
        "# ===== Dataset 1: √âquilibr√© (50-50) =====\n",
        "def create_balanced_dataset(benign, malicious, total_size=176883):\n",
        "    \"\"\"\n",
        "    Cr√©e un dataset √©quilibr√© avec 50% benign et 50% malicious\n",
        "    \"\"\"\n",
        "    size_per_class = total_size // 2  #  176883 // 2 = 88441 pour chaque classe\n",
        "\n",
        "    ben_sample = benign.sample(n=size_per_class, random_state=42)\n",
        "    mal_sample = malicious.sample(n=size_per_class, random_state=42)\n",
        "\n",
        "    dataset = pd.concat([ben_sample, mal_sample]) # Concat√®ne  les deux DataFrames\n",
        "    dataset = dataset.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "    return dataset\n",
        "\n",
        "# ===== Dataset 2: 90% b√©nignes, 10% malveillantes =====\n",
        "def create_imbalanced_dataset_90_10(benign, malicious, total_size=176883):\n",
        "    \"\"\"\n",
        "    Cr√©e un dataset avec 90% benign et 10% malicious\n",
        "    \"\"\"\n",
        "    ben_size = int(total_size * 0.9)\n",
        "    mal_size = int(total_size * 0.1)\n",
        "\n",
        "    ben_sample = benign.sample(n=ben_size, random_state=42)\n",
        "    mal_sample = malicious.sample(n=mal_size, random_state=42)\n",
        "\n",
        "    dataset = pd.concat([ben_sample, mal_sample])\n",
        "    dataset = dataset.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "    return dataset\n",
        "\n",
        "# ===== Dataset 3: 10% b√©nignes, 90% malveillantes =====\n",
        "def create_imbalanced_dataset_10_90(benign, malicious, total_size=176883):\n",
        "    \"\"\"\n",
        "    Cr√©e un dataset avec 10% benign et 90% malicious\n",
        "    \"\"\"\n",
        "    ben_size = int(total_size * 0.1)\n",
        "    mal_size = int(total_size * 0.9)\n",
        "\n",
        "    ben_sample = benign.sample(n=ben_size, random_state=42)\n",
        "    mal_sample = malicious.sample(n=mal_size, random_state=42)\n",
        "\n",
        "    dataset = pd.concat([ben_sample, mal_sample])\n",
        "    dataset = dataset.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "    return dataset\n",
        "\n",
        "# ===== Cr√©er les 3 datasets =====\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"CR√âATION DES DATASETS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "dataset_balanced = create_balanced_dataset(benign, malicious, TOTAL_SIZE)\n",
        "dataset_imb_90_10 = create_imbalanced_dataset_90_10(benign, malicious, TOTAL_SIZE)\n",
        "dataset_imb_10_90 = create_imbalanced_dataset_10_90(benign, malicious, TOTAL_SIZE)\n",
        "\n",
        "# ===== Afficher les statistiques =====\n",
        "print(\"\\nüìä DATASET 1 - BALANCED (50-50):\")\n",
        "print(f\"   Total samples: {len(dataset_balanced)}\")\n",
        "print(f\"   Distribution:\")\n",
        "print(dataset_balanced['label'].value_counts().sort_index())\n",
        "print(f\"   Pourcentages:\")\n",
        "print(dataset_balanced['label'].value_counts(normalize=True).sort_index() * 100)\n",
        "\n",
        "print(\"\\nüìä DATASET 2 - IMBALANCED (90% benign - 10% malicious):\")\n",
        "print(f\"   Total samples: {len(dataset_imb_90_10)}\")\n",
        "print(f\"   Distribution:\")\n",
        "print(dataset_imb_90_10['label'].value_counts().sort_index())\n",
        "print(f\"   Pourcentages:\")\n",
        "print(dataset_imb_90_10['label'].value_counts(normalize=True).sort_index() * 100)\n",
        "\n",
        "print(\"\\nüìä DATASET 3 - IMBALANCED (10% benign - 90% malicious):\")\n",
        "print(f\"   Total samples: {len(dataset_imb_10_90)}\")\n",
        "print(f\"   Distribution:\")\n",
        "print(dataset_imb_10_90['label'].value_counts().sort_index())\n",
        "print(f\"   Pourcentages:\")\n",
        "print(dataset_imb_10_90['label'].value_counts(normalize=True).sort_index() * 100)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xbCP8QRMI75Z"
      },
      "source": [
        "Charge le tokenizer RoBERTa pr√©-entra√Æn√©"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DCnLEyVAf5Vm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "acca6ccd-f8f9-4926-e27d-f1524c3dacab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets) (3.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.12/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.36.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from datasets) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets) (6.0.3)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.13.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets) (1.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (2026.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.22.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T6qTTSBagclo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d0dfb61-4381-4574-d9da-784d5dec9901"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.6)\n",
            "Requirement already satisfied: peft in /usr/local/lib/python3.12/dist-packages (0.18.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.7.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from peft) (5.9.5)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.12/dist-packages (from peft) (2.9.0+cu126)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from peft) (1.12.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (3.5.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2026.1.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.13.0->peft) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.13.0->peft) (3.0.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers peft\n",
        "import torch\n",
        "from datasets import Dataset\n",
        "from transformers import RobertaTokenizerFast"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EkOVrxGSfu_o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b84c80ee-73ba-4ac0-e2c6-b76da5027e52"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenizer charg√© avec succ√®s!\n",
            "Taille du vocabulaire: 50265\n"
          ]
        }
      ],
      "source": [
        "#Charge le tokenizer RoBERTa pr√©-entra√Æn√©, qui convertit les URLs en tokens num√©riques exploitables par le mod√®le.\n",
        "tokenizer = RobertaTokenizerFast.from_pretrained(\"roberta-base\")  #Ce bloc charge le tokenizer RoBERTa, mais pas le mod√®le lui-m√™me.\n",
        "#Confirme le chargement correct du tokenizer et affiche la taille de son vocabulaire.\n",
        "print(\"Tokenizer charg√© avec succ√®s!\")\n",
        "print(f\"Taille du vocabulaire: {tokenizer.vocab_size}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NNLC984agrUY"
      },
      "source": [
        "D√©finir la fonction de tokenisation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i6aXjTr5mRV-"
      },
      "outputs": [],
      "source": [
        "# √âTAPE 2 : D√©finir la fonction de tokenisation pour tokeniser un batch de donn√©es\n",
        "def tokenize_batch(batch):\n",
        "    return tokenizer(\n",
        "        batch[\"url\"],#le texte (URLs) √† convertir en tokens\n",
        "        truncation=True,  #Si le texte est trop long, on ne garde que les 128 premiers tokens\n",
        "        padding=\"max_length\",  #padding=\"max_length\" Tous les textes doivent avoir la m√™me longueur+remplit les textes courts jusqu‚Äô√† max_length\n",
        "        max_length=128 #limite les s√©quences √† 128 tokens\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YzJm7N-1nO4B"
      },
      "source": [
        " convertir les 3 dataFrames pandas en HuggingFace Dataset, RoBERTa + Trainer ne travaillent pas directement avec pandas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UZJtdWNxn8g4"
      },
      "outputs": [],
      "source": [
        "#Conversion des datasets Pandas en huggingface dataset\n",
        "hf_balanced = Dataset.from_pandas(dataset_balanced)\n",
        "hf_90_10 = Dataset.from_pandas(dataset_imb_90_10)  #(90% benign - 10% malicious)\n",
        "hf_10_90 = Dataset.from_pandas(dataset_imb_10_90)  #(10% benign - 90% malicious)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltnDRhj2oLeg"
      },
      "source": [
        "Appliquer le tokenizer RoBERTa aux 3 datasets, Obtenir des datasets pr√™ts pour l‚Äôentra√Ænement"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bXiOvGcso5LD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "3c5bf40d88c349a2bdce9e7e828fdebb",
            "918807df81ab4629aa802f9651c64520",
            "8847cdcf07e44ef89d3fe161ef3fe39f",
            "4f3d97f355034696aee838d0265004c4",
            "be2420ebd3c5407b84e67a6bcf2f328c",
            "5dabba6a028e47578502bfaa55041e92",
            "24bd94034feb4413bb180a89bba68f0a",
            "0a2ec6fde69f4f87be5ec771306ccf35",
            "be6856883078427a97af647cf5a4b9e1",
            "9c4c6692bdf040b088e17d55cc1663ff",
            "c3f368f022c44069b54beaaa62cbd0d4"
          ]
        },
        "outputId": "c847fd0c-3488-443d-d974-f7d1c53a597f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/176882 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3c5bf40d88c349a2bdce9e7e828fdebb"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Tokenisation du dataset √©quilibr√© (50‚Äì50)\n",
        "hf_balanced = hf_balanced.map(\n",
        "    tokenize_batch,#Applique la fonction tokenize_batch en batch sur le dataset Hugging Face.\n",
        "    batched=True,#Traiter les donn√©es par lots (ex: 1000 lignes √† la fois) au lieu d'une par une Taille du batch par d√©faut : 1000 lignes/ traitement vectoris√©, plus rapide pour les grands datasets.\n",
        "    remove_columns=[\"url\"]# le mod√®le n‚Äôa besoin que des input_ids et attention_mask. on garde seulement les features n√©cessaires\n",
        ")\n",
        "#Taille du batch non pr√©cis√©e ‚Üí Hugging Face utilise 1000 par d√©faut, mais peut √™tre ajust√©e si GPU limit√©."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EPyqhrDdpl_A",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "850d148ee10b4f4e8f2031e5c890fbf3",
            "2d6f195304304e369cdfaa96801b4a05",
            "1076c11cac3542d9945c6783369710f3",
            "66787da1fffe4eae861ca61f561f442d",
            "37943b266f6e4c628042bbf19ff2f0c4",
            "f29329bd063a4a7b93cdf656d1940708",
            "5ce847f1fa4a44e1ba3818686e34053d",
            "6ceace4679094479814b68f64d469019",
            "f27ccf5a07944db1b9b0c0abce116f6c",
            "b20557e7cd8b45a9ab77c32f936658e2",
            "751b7e14eccc411d843dd316aa7c7637"
          ]
        },
        "outputId": "cfa55159-42c4-4d39-e0ac-6919909568d3"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/176882 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "850d148ee10b4f4e8f2031e5c890fbf3"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "#Tokenisation du dataset 10‚Äì90\n",
        "hf_10_90 = hf_10_90.map(\n",
        "    tokenize_batch,\n",
        "    batched=True,\n",
        "    remove_columns=[\"url\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BAlHOO9CpoDc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "fa700f39a8234331ba2d73a1e4702b7a",
            "18eb0d348548430a84e2986338136297",
            "dd0dc81974fe4819b3d72f637f272ed2",
            "6ea502fb6d6a404fb52111fe62d2416b",
            "3ef289bb25f94e1c90a3c6511a17dfd9",
            "6941e5d8f28d4b4da8f51ec600184832",
            "42b35495b0284da19bae36d815646b49",
            "5f52851131774742ac4ce50c509d3d5a",
            "c7c411e6e3cd4d20b914cf7154f6fe90",
            "2ae77b4cffee477f9285107a4d398d62",
            "5d700c7f05fa4e41a04c1170d2a3818d"
          ]
        },
        "outputId": "3f6d0237-d1aa-4ece-e096-97c9464123d2"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/176882 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fa700f39a8234331ba2d73a1e4702b7a"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "#Tokenisation du dataset 90‚Äì10\n",
        "hf_90_10 = hf_90_10.map(\n",
        "    tokenize_batch,\n",
        "    batched=True,\n",
        "    remove_columns=[\"url\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ffqFEdop_yB"
      },
      "source": [
        "D√©finir le format PyTorch:Convertit les datasets HF en tenseurs PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xSWEJS6ZqDFr"
      },
      "outputs": [],
      "source": [
        "columns = [\"input_ids\", \"attention_mask\", \"label\"] #Sp√©cifie les colonnes que le mod√®le RoBERTa utilisera pour l‚Äôentra√Ænement\n",
        "#Convertit les datasets HF en tenseurs PyTorch, pr√™ts pour l‚Äôentra√Ænement,  Ne garde que les colonnes sp√©cifi√©es (input_ids, attention_mask, label) ‚Üí optimisation m√©moire.\n",
        "hf_balanced.set_format(type=\"torch\", columns=columns)\n",
        "hf_90_10.set_format(type=\"torch\", columns=columns)\n",
        "hf_10_90.set_format(type=\"torch\", columns=columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VvP5Kq7FqruR"
      },
      "source": [
        "Affichage pour faire la v√©rification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z3VHxdj7pyXI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b514ce0b-9db4-4fc0-a21c-8947d86712ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset({\n",
            "    features: ['label', 'input_ids', 'attention_mask'],\n",
            "    num_rows: 176882\n",
            "})\n",
            "Dataset({\n",
            "    features: ['label', 'input_ids', 'attention_mask'],\n",
            "    num_rows: 176882\n",
            "})\n",
            "Dataset({\n",
            "    features: ['label', 'input_ids', 'attention_mask'],\n",
            "    num_rows: 176882\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "print(hf_balanced)\n",
        "print(hf_90_10)\n",
        "print(hf_10_90)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cu3aHNXOq7ZV"
      },
      "source": [
        "S√©paration des donn√©es (TRAIN / TEST (80%-20%)) pour les 3 dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "76T6DDbbrF3S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a695b168-c565-4321-a9fe-129c1b2eddc6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Balanced Dataset\n",
            "Train size: 141505\n",
            "Test size : 35377\n"
          ]
        }
      ],
      "source": [
        "#S√©pare le dataset Hugging Face en train (80%) et test (20%) dataset 50%-50%\n",
        "split_balanced = hf_balanced.train_test_split(test_size=0.2, seed=42)\n",
        "train_balanced = split_balanced[\"train\"]\n",
        "test_balanced = split_balanced[\"test\"]\n",
        "\n",
        "# V√©rification affiche le nombre d‚Äô√©chantillons pour train et test afin de v√©rifier le split.\n",
        "print(\"Balanced Dataset\")\n",
        "print(\"Train size:\", len(train_balanced))\n",
        "print(\"Test size :\", len(test_balanced))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Mp9rtX70SYb"
      },
      "outputs": [],
      "source": [
        "# dataset 90%-10%\n",
        "split_90_10 = hf_90_10.train_test_split(test_size=0.2, seed=42)\n",
        "train_90_10 = split_90_10[\"train\"]\n",
        "test_90_10 = split_90_10[\"test\"]\n",
        "\n",
        "# dataset 10%-90%\n",
        "split_10_90 = hf_10_90.train_test_split(test_size=0.2, seed=42)\n",
        "train_10_90 = split_10_90[\"train\"]\n",
        "test_10_90 = split_10_90[\"test\"]\n",
        "#V√©rification similaire pour chacun (taille + distribution)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8FyL_25h0qGG"
      },
      "source": [
        "FINE-TUNING AVEC LoRA\n",
        "\n",
        "Si tu entra√Ænes le mod√®le sur balanced puis tu r√©-entra√Æne sur 90/10 avec le m√™me objet model, tu ‚Äúcontamines‚Äù l‚Äôexp√©rience (carry-over).\n",
        "\n",
        "‚û°Ô∏è Tu dois recr√©er un mod√®le neuf (m√™mes poids init) pour chaque dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "66MYdclZAoJh"
      },
      "outputs": [],
      "source": [
        "from peft import LoraConfig,TaskType,get_peft_model #outils pour appliquer LoRA\n",
        "#Tokenizer:convertit le texte en tokens (input_ids, attention_mask) deja charger, On charge le mod√®le RoBERTa pour la classification binaire il re√ßoit ces tokens et produit des pr√©dictions/ classification\n",
        "def build_lora_roberta():\n",
        "# Charger mod√®le pr√©-entra√Æn√©\n",
        "    base = RobertaForSequenceClassification.from_pretrained(\"roberta-base\", num_labels=2) #D√©finit num_labels=2 pour la classification binaire (benign/malicious).\n",
        "#la taille du mod√®le est grande (~125M param√®tres) ‚Üí GPU n√©cessaire pour fine-tuning complet, LoRA r√©duit ce co√ªt.\n",
        "#Param√®tres standard pour fine-tuning efficace avec LoRA (Configuration LoRA )\n",
        "    lora_config = LoraConfig(\n",
        "        r=8, #rang de la d√©composition low-rank ‚Üí contr√¥le la capacit√© d‚Äôadaptation\n",
        "        lora_alpha=16,\n",
        "        lora_dropout=0.1,\n",
        "        target_modules=[\"query\", \"value\"],#appliqu√© uniquement aux matrices Q et V des transformers\n",
        "        bias=\"none\",\n",
        "        task_type=TaskType.SEQ_CLS # Sequence Classification, t√¢che de classification de s√©quences\n",
        "    )\n",
        "    #  Appliquer LoRA au mod√®le,Transforme le mod√®le RoBERTa en mod√®le LoRA, o√π seules certaines couches sont entra√Ænables.\n",
        "    model = get_peft_model(base, lora_config)\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kWH5kLeH3AnQ"
      },
      "source": [
        "Pr√©parer l‚Äôentra√Ænement"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PPkPYJd83Ej3"
      },
      "outputs": [],
      "source": [
        "from transformers import TrainingArguments\n",
        "from transformers import Trainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XAi3dcCk3BQj"
      },
      "outputs": [],
      "source": [
        "# TrainingArguments : classe qui permet de d√©finir tous les param√®tres d‚Äôentra√Ænement du mod√®le, Nombre d‚Äôepochs, taille des batches, learning rate, Strat√©gie d‚Äô√©valuation et de sauvegarde GPU/FP16, logging, etc.\n",
        "#Trainer : classe qui g√®re automatiquement l‚Äôentra√Ænement, l‚Äô√©valuation et la sauvegarde du mod√®le, automatisera tout l‚Äôentra√Ænement : forward/backward pass, calcul de loss, optimisation, scheduler, checkpointing.\n",
        "#Trainer appelle automatiquement  fonction compte metric √† chaque √©valuation (eval_dataset).\n",
        "#output_dir doit √™tre diff√©rent pour chaque exp√©rience,Sinon tu √©crases les r√©sultats du balanced avec ceux du 90/10 etc.\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results/balanced\", # dossier pour sauvegarder les checkpoints\n",
        "    num_train_epochs=1, #nombre de passages sur tout le dataset\n",
        "    per_device_train_batch_size=16, # batch size pour l'entra√Ænement\n",
        "    per_device_eval_batch_size=32,# batch size pour √©valuation\n",
        "    learning_rate=5e-5,\n",
        "    save_strategy=\"epoch\", # sauvegarder mod√®le √† chaque epoch\n",
        "    eval_strategy=\"epoch\", # Added evaluation strategy , √©valuer √† chaque fin d'epoch\n",
        "    fp16=True  # activer float16 si GPU compatible\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KVL-ZFqL5xup"
      },
      "source": [
        "Fonction d‚Äô√©valuation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uRZ15vlB5ybH"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kmjCp6th51Ct"
      },
      "outputs": [],
      "source": [
        "#calculer des m√©triques personnalis√©es (precision, recall, F1-score) pendant l‚Äô√©valuation.\n",
        "def compute_metrics(eval_pred):\n",
        "    \"\"\"\n",
        "    Cette fonction est appel√©e par Trainer √† chaque √©valuation.\n",
        "    eval_pred: tuple (logits, labels)\n",
        "    Retourne: dictionnaire {\"precision\":..., \"recall\":..., \"f1\":...}\n",
        "    \"\"\"\n",
        "    #Entr√©e : un tuple (logits, labels), Sortie : dictionnaire avec les m√©triques, compatible avec HF Trainer.\n",
        "    logits, labels = eval_pred\n",
        "    # Convertir logits en pr√©dictions de classe\n",
        "    preds = torch.argmax(torch.tensor(logits), axis=1).numpy()\n",
        "    labels = labels.astype(int)\n",
        "\n",
        "    # Calcul des m√©triques\n",
        "    precision = precision_score(labels, preds)\n",
        "    recall = recall_score(labels, preds)\n",
        "    f1 = f1_score(labels, preds)\n",
        "\n",
        "    return {\n",
        "        \"precision\": precision,\n",
        "        \"recall\": recall,\n",
        "        \"f1\": f1\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rPZVz41xKWXD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1f16577-77a8-44b2-aa71-34a65f716c1c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "print(torch.cuda.is_available())  #entra√Ænement sur GPU\n",
        "#Cette fonction v√©rifie si CUDA est disponible sur ta machine. CUDA est la technologie de NVIDIA qui permet d‚Äôutiliser le GPU pour les calculs.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lP4n9a3MKutL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "133925fd-41d0-4fc2-fb9a-801f1645e51f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Aucun GPU CUDA d√©tect√©\n"
          ]
        }
      ],
      "source": [
        "if torch.cuda.is_available():\n",
        "    print(torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    print(\"Aucun GPU CUDA d√©tect√©\")\n",
        "\n",
        "\n",
        "\n",
        "#|# Mat√©riel | Temps attendu (1 epoch) |\n",
        "#| --------  | ----------------------- |\n",
        "#| CPU      |  20‚Äì100 h                |\n",
        "#| GPU T4   | ~30‚Äì60 min               |\n",
        "#| GPU V100 | ~20‚Äì40 min               |\n",
        "#| GPU A100 | ~5‚Äì10 min                |\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ppn0p8Au5_kT"
      },
      "source": [
        "Cr√©er Trainer+ Lancer l'entra√Ænement balanced dataset+calcul les metric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p-p_Q6gF6Oca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "outputId": "d2d5fc30-d67d-4983-9583-99014e14e3ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-342867030.py:6: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer_balanced = Trainer(\n",
            "/usr/local/lib/python3.12/dist-packages/notebook/notebookapp.py:191: SyntaxWarning: invalid escape sequence '\\/'\n",
            "  | |_| | '_ \\/ _` / _` |  _/ -_)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: You chose \"Don't visualize my results\"\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using W&B in offline mode.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.24.0"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "W&B syncing is set to <code>`offline`<code> in this directory. Run <code>`wandb online`<code> or set <code>WANDB_MODE=online<code> to enable cloud syncing.<br>Run data is saved locally in <code>/content/wandb/offline-run-20260124_042523-cre3cwuu</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='8845' max='8845' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [8845/8845 13:33, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.029600</td>\n",
              "      <td>0.038734</td>\n",
              "      <td>0.998916</td>\n",
              "      <td>0.987260</td>\n",
              "      <td>0.993054</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=8845, training_loss=0.047916477908516684, metrics={'train_runtime': 827.955, 'train_samples_per_second': 170.909, 'train_steps_per_second': 10.683, 'total_flos': 9404282506644480.0, 'train_loss': 0.047916477908516684, 'epoch': 1.0})"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "from transformers import RobertaForSequenceClassification, RobertaTokenizer\n",
        "\n",
        "# IMPORTANT: nouveau mod√®le pour chaque exp√©rience\n",
        "model_balanced = build_lora_roberta()\n",
        "#Cr√©er Trainer\n",
        "trainer_balanced = Trainer(\n",
        "   model= model_balanced,\n",
        "    args=training_args,\n",
        "    train_dataset=train_balanced, #  avec dataset √©quilibr√©\n",
        "    eval_dataset=test_balanced,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "# Lancer l'entra√Ænement\n",
        "trainer_balanced.train() # entra√Æne le mod√®le en appliquant LoRA sur les couches cibl√©es"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dRaxNYgT6Psh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "outputId": "4beabbb8-dd34-4e6d-84e5-49ea15a57f8f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1106' max='1106' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1106/1106 01:05]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R√©sultats finaux sur balanced dataset de test :\n",
            "{'eval_loss': 0.038733527064323425, 'eval_precision': 0.9989162673967602, 'eval_recall': 0.9872597102429674, 'eval_f1': 0.9930537835615662, 'eval_runtime': 65.9942, 'eval_samples_per_second': 536.062, 'eval_steps_per_second': 16.759, 'epoch': 1.0}\n"
          ]
        }
      ],
      "source": [
        "#√©value le mod√®le sur le dataset de test. Retourne un dictionnaire avec loss et m√©triques ( precision, recall, F1).\n",
        "metrics = trainer_balanced.evaluate()  # √©value le mod√®le sur le dataset de test\n",
        "#evaluate() est une m√©thode fournie par la classe Trainer de Hugging Face.\n",
        "#Trainer fait automatiquement : Passe le mod√®le en mode √©valuation (model.eval())\n",
        "\n",
        "#Calcule :  Validation loss (automatique), Les m√©triques d√©finies dans compute_metrics, Retourne un dictionnaire de r√©sultats\n",
        "print(\"R√©sultats finaux sur balanced dataset de test :\")\n",
        "print(metrics)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mdn9IfKs6Pd4"
      },
      "source": [
        "Lancer l'entra√Ænement 90-10 dataset+ calcul les metric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2nbvy6I4GBit"
      },
      "outputs": [],
      "source": [
        "#change output_dir pour chaque experience +Toujours construire un mod√®le neuf\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results/90-10-dataset\", # dossier pour sauvegarder les checkpoints\n",
        "    num_train_epochs=1, #nombre de passages sur tout le dataset\n",
        "    per_device_train_batch_size=16, # batch size pour l'entra√Ænement\n",
        "    per_device_eval_batch_size=32,# batch size pour √©valuation\n",
        "    learning_rate=5e-5,\n",
        "    save_strategy=\"epoch\", # sauvegarder mod√®le √† chaque epoch\n",
        "    eval_strategy=\"epoch\", # Added evaluation strategy , √©valuer √† chaque fin d'epoch\n",
        "    fp16=True  # activer float16 si GPU compatible\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vX32LGSv6f8h",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "outputId": "7d9b007b-126a-4afe-9691-a36d35faa942"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-2001469779.py:2: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer_90_10 = Trainer(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='8845' max='8845' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [8845/8845 13:07, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.020400</td>\n",
              "      <td>0.019273</td>\n",
              "      <td>0.994937</td>\n",
              "      <td>0.980050</td>\n",
              "      <td>0.987437</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=8845, training_loss=0.02585402796536667, metrics={'train_runtime': 787.3936, 'train_samples_per_second': 179.713, 'train_steps_per_second': 11.233, 'total_flos': 9404282506644480.0, 'train_loss': 0.02585402796536667, 'epoch': 1.0})"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "model_90_10=build_lora_roberta()\n",
        "trainer_90_10 = Trainer(\n",
        "   model= model_90_10,\n",
        "    args=training_args,\n",
        "    train_dataset=train_90_10,\n",
        "    eval_dataset=test_90_10,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "trainer_90_10.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wO5vRp530sXK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "outputId": "64e9fb9d-0a3c-4d20-da41-1a10bf50dec2"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1106' max='1106' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1106/1106 01:04]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R√©sultats finaux sur 90-10 dataset de test :\n",
            "{'eval_loss': 0.019273225218057632, 'eval_precision': 0.9949367088607595, 'eval_recall': 0.9800498753117207, 'eval_f1': 0.9874371859296482, 'eval_runtime': 65.0434, 'eval_samples_per_second': 543.899, 'eval_steps_per_second': 17.004, 'epoch': 1.0}\n"
          ]
        }
      ],
      "source": [
        "metrics = trainer_90_10.evaluate()\n",
        "print(\"R√©sultats finaux sur 90-10 dataset de test :\")\n",
        "print(metrics)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AR0MQtbB1RdT"
      },
      "source": [
        "Lancer l'entra√Ænement 10-90 dataset+ calcul les metric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B48o1Um5GaNC"
      },
      "outputs": [],
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results/10-90-dataset\", # dossier pour sauvegarder les checkpoints\n",
        "    num_train_epochs=1, #nombre de passages sur tout le dataset\n",
        "    per_device_train_batch_size=16, # batch size pour l'entra√Ænement\n",
        "    per_device_eval_batch_size=32,# batch size pour √©valuation\n",
        "    learning_rate=5e-5,\n",
        "    save_strategy=\"epoch\", # sauvegarder mod√®le √† chaque epoch\n",
        "    eval_strategy=\"epoch\", # Added evaluation strategy , √©valuer √† chaque fin d'epoch\n",
        "    fp16=True  # activer float16 si GPU compatible\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vptqPWs66hPJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "outputId": "76b2ffb7-2a5a-408a-eda2-0feda021f78f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-610124807.py:2: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer_10_90 = Trainer(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='8845' max='8845' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [8845/8845 13:38, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.019900</td>\n",
              "      <td>0.031882</td>\n",
              "      <td>0.999399</td>\n",
              "      <td>0.991587</td>\n",
              "      <td>0.995478</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=8845, training_loss=0.03781309812469224, metrics={'train_runtime': 819.0861, 'train_samples_per_second': 172.76, 'train_steps_per_second': 10.799, 'total_flos': 9404282506644480.0, 'train_loss': 0.03781309812469224, 'epoch': 1.0})"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "model_10_90=build_lora_roberta()\n",
        "trainer_10_90 = Trainer(\n",
        "    model=model_10_90,\n",
        "    args=training_args,\n",
        "    train_dataset=train_10_90,\n",
        "    eval_dataset=test_10_90,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "trainer_10_90.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UO2YGVLY0-u6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "outputId": "3474dd8a-3236-4ebd-fa73-ecd21b4fef2b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1106' max='1106' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1106/1106 01:05]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R√©sultats finaux sur 10-90 dataset de test :\n",
            "{'eval_loss': 0.03188216686248779, 'eval_precision': 0.9993988673395134, 'eval_recall': 0.9915871421396283, 'eval_f1': 0.9954776799079779, 'eval_runtime': 65.4635, 'eval_samples_per_second': 540.408, 'eval_steps_per_second': 16.895, 'epoch': 1.0}\n"
          ]
        }
      ],
      "source": [
        "metrics = trainer_10_90.evaluate()\n",
        "print(\"R√©sultats finaux sur 10-90 dataset de test :\")\n",
        "print(metrics)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNGWEuQRJsc8LQWm4p0cHWj",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3c5bf40d88c349a2bdce9e7e828fdebb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_918807df81ab4629aa802f9651c64520",
              "IPY_MODEL_8847cdcf07e44ef89d3fe161ef3fe39f",
              "IPY_MODEL_4f3d97f355034696aee838d0265004c4"
            ],
            "layout": "IPY_MODEL_be2420ebd3c5407b84e67a6bcf2f328c"
          }
        },
        "918807df81ab4629aa802f9651c64520": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5dabba6a028e47578502bfaa55041e92",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_24bd94034feb4413bb180a89bba68f0a",
            "value": "Map:‚Äá100%"
          }
        },
        "8847cdcf07e44ef89d3fe161ef3fe39f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0a2ec6fde69f4f87be5ec771306ccf35",
            "max": 176882,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_be6856883078427a97af647cf5a4b9e1",
            "value": 176882
          }
        },
        "4f3d97f355034696aee838d0265004c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9c4c6692bdf040b088e17d55cc1663ff",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_c3f368f022c44069b54beaaa62cbd0d4",
            "value": "‚Äá176882/176882‚Äá[00:50&lt;00:00,‚Äá4418.50‚Äáexamples/s]"
          }
        },
        "be2420ebd3c5407b84e67a6bcf2f328c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5dabba6a028e47578502bfaa55041e92": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "24bd94034feb4413bb180a89bba68f0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0a2ec6fde69f4f87be5ec771306ccf35": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be6856883078427a97af647cf5a4b9e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9c4c6692bdf040b088e17d55cc1663ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3f368f022c44069b54beaaa62cbd0d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "850d148ee10b4f4e8f2031e5c890fbf3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2d6f195304304e369cdfaa96801b4a05",
              "IPY_MODEL_1076c11cac3542d9945c6783369710f3",
              "IPY_MODEL_66787da1fffe4eae861ca61f561f442d"
            ],
            "layout": "IPY_MODEL_37943b266f6e4c628042bbf19ff2f0c4"
          }
        },
        "2d6f195304304e369cdfaa96801b4a05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f29329bd063a4a7b93cdf656d1940708",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_5ce847f1fa4a44e1ba3818686e34053d",
            "value": "Map:‚Äá100%"
          }
        },
        "1076c11cac3542d9945c6783369710f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6ceace4679094479814b68f64d469019",
            "max": 176882,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f27ccf5a07944db1b9b0c0abce116f6c",
            "value": 176882
          }
        },
        "66787da1fffe4eae861ca61f561f442d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b20557e7cd8b45a9ab77c32f936658e2",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_751b7e14eccc411d843dd316aa7c7637",
            "value": "‚Äá176882/176882‚Äá[00:23&lt;00:00,‚Äá5325.48‚Äáexamples/s]"
          }
        },
        "37943b266f6e4c628042bbf19ff2f0c4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f29329bd063a4a7b93cdf656d1940708": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5ce847f1fa4a44e1ba3818686e34053d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6ceace4679094479814b68f64d469019": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f27ccf5a07944db1b9b0c0abce116f6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b20557e7cd8b45a9ab77c32f936658e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "751b7e14eccc411d843dd316aa7c7637": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fa700f39a8234331ba2d73a1e4702b7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_18eb0d348548430a84e2986338136297",
              "IPY_MODEL_dd0dc81974fe4819b3d72f637f272ed2",
              "IPY_MODEL_6ea502fb6d6a404fb52111fe62d2416b"
            ],
            "layout": "IPY_MODEL_3ef289bb25f94e1c90a3c6511a17dfd9"
          }
        },
        "18eb0d348548430a84e2986338136297": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6941e5d8f28d4b4da8f51ec600184832",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_42b35495b0284da19bae36d815646b49",
            "value": "Map:‚Äá100%"
          }
        },
        "dd0dc81974fe4819b3d72f637f272ed2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5f52851131774742ac4ce50c509d3d5a",
            "max": 176882,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c7c411e6e3cd4d20b914cf7154f6fe90",
            "value": 176882
          }
        },
        "6ea502fb6d6a404fb52111fe62d2416b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2ae77b4cffee477f9285107a4d398d62",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_5d700c7f05fa4e41a04c1170d2a3818d",
            "value": "‚Äá176882/176882‚Äá[00:22&lt;00:00,‚Äá5496.01‚Äáexamples/s]"
          }
        },
        "3ef289bb25f94e1c90a3c6511a17dfd9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6941e5d8f28d4b4da8f51ec600184832": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "42b35495b0284da19bae36d815646b49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5f52851131774742ac4ce50c509d3d5a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c7c411e6e3cd4d20b914cf7154f6fe90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2ae77b4cffee477f9285107a4d398d62": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5d700c7f05fa4e41a04c1170d2a3818d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}